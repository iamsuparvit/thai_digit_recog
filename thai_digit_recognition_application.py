# -*- coding: utf-8 -*-
"""Thai Digit Recognition Application

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-4_QKKR3Nqbl_C_HSrgWwQBzQ_8gla6D
"""

import numpy as np
import torch
from pathlib import Path
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms
import gradio as gr

#!pip install gradio==3.35.0
#!pip install torchvision

!wget https://github.com/iamsuparvit/thai_digit_recog/raw/refs/heads/main/thai_digit_recog_model.pth

class DropoutThaiDigit(nn.Module):
    def __init__(self):
        super(DropoutThaiDigit, self).__init__()
        self.layers = nn.Sequential(
            nn.Linear(28*28, 392),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(392, 196),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(196, 98),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(98, 10),
        )

    def forward(self, x):
        x = x.view(-1, 28 * 28)
        return self.layers(x)

# Load best model
model_path = "thai_digit_recog_model.pth"
model = DropoutThaiDigit()  # initialize the model
# load the model weights, specifying the device to cuda
model.load_state_dict(torch.load(model_path, map_location=torch.device("cpu")))

model.eval()

transform = transforms.Compose([
    transforms.Resize((28, 28)),
    transforms.Grayscale(),
    transforms.ToTensor()
])

labels = ["๐ (ศูนย์)", "๑ (หนึ่ง)", "๒ (สอง)", "๓ (สาม)", "๔ (สี่)", "๕ (ห้า)", "๖ (หก)", "๗ (เจ็ด)", "๘ (แปด)", "๙ (เก้า)"]
LABELS = {i:k for i, k in enumerate(labels)} # dictionary of index and label

def predict(img):
    """
    Predict function takes image and return top 5 predictions
    as a dictionary:

        {label: confidence, label: confidence, ...}
    """
    if img is None:
        return None
    img = transform(img)  # do not need to use 1 - transform(img) because gradio already do it
    probs = model(img).softmax(dim=1).ravel()
    probs, indices = torch.topk(probs, 5)  # select top 5
    probs, indices = probs.tolist(), indices.tolist()  # transform to list
    confidences = {LABELS[i]: v for i, v in zip(indices, probs)}
    return confidences

demo = gr.Interface(
    fn=predict,
    inputs=gr.Sketchpad(label="Draw Here", brush_radius=5, type="pil", shape=(120, 120)),
    outputs=gr.Label(label="Prediction"),
    title="Thai Digit Handwritten Classification",
    live=True
)

demo.launch()
